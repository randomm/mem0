[pgvector](https://github.com/pgvector/pgvector) is open-source vector similarity search for Postgres. After connecting with postgres run `CREATE EXTENSION IF NOT EXISTS vector;` to create the vector extension.

### Usage

```python
import os
from mem0 import Memory

os.environ["OPENAI_API_KEY"] = "sk-xx"

config = {
    "vector_store": {
        "provider": "pgvector",
        "config": {
            "user": "test",
            "password": "123",
            "host": "127.0.0.1",
            "port": "5432",
        }
    }
}

m = Memory.from_config(config)
messages = [
    {"role": "user", "content": "I'm planning to watch a movie tonight. Any recommendations?"},
    {"role": "assistant", "content": "How about a thriller movies? They can be quite engaging."},
    {"role": "user", "content": "I'm not a big fan of thriller movies but I love sci-fi movies."},
    {"role": "assistant", "content": "Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future."}
]
m.add(messages, user_id="alice", metadata={"category": "movies"})
```

### Config

Here's the parameters available for configuring pgvector:

| Parameter | Description | Default Value |
| --- | --- | --- |
| `dbname` | The name of the  | `postgres` |
| `collection_name` | The name of the collection | `mem0` |
| `embedding_model_dims` | Dimensions of the embedding model | `1536` |
| `user` | User name to connect to the database | `None` |
| `password` | Password to connect to the database | `None` |
| `host` | The host where the Postgres server is running | `None` |
| `port` | The port where the Postgres server is running | `None` |
| `diskann` | Whether to use diskann for vector similarity search (requires pgvectorscale) | `True` |
| `hnsw` | Whether to use hnsw for vector similarity search | `False` |
| `quantization` | (Optional) Dictionary to enable vector quantization (currently supports binary). Example: `{"precision": "binary"}` or `{"precision": "ubinary"}`. Requires `sentence-transformers` installed. If enabled, `diskann` is automatically disabled. | `None` |
| `matryoshka_dims` | (Optional) Target dimensions for Matryoshka embedding truncation. Must be less than `embedding_model_dims`. Used with models like Jina embeddings v3 that support dimension truncation. | `None` |

### Binary Quantization

You can enable binary quantization for `pgvector` to significantly reduce storage size and potentially speed up searches using Hamming distance. This feature requires the `sentence-transformers` library to be installed (`pip install sentence-transformers`).

To enable it, add the `quantization` dictionary to the `config`:

```python
config = {
    "vector_store": {
        "provider": "pgvector",
        "config": {
            "user": "test",
            "password": "123",
            "host": "127.0.0.1",
            "port": "5432",
            "quantization": {
                "precision": "binary"  # Or "ubinary"
            }
            # embedding_model_dims should still be the original float dimension (e.g., 1024)
        }
    }
}
```

**Notes:**

*   Set `precision` to either `"binary"` (produces `int8` packed vectors) or `"ubinary"` (produces `uint8` packed vectors).
*   The `embedding_model_dims` should still reflect the original dimensions of your float embeddings (e.g., 1024), not the reduced dimensions after packing (e.g., 128).
*   When quantization is enabled, the `diskann` option is ignored (set to `False`) as it likely doesn't support the `BIT` vector type. `hnsw` can still be enabled (`True`) and will use Hamming distance.
*   Quantization involves a trade-off: reduced storage/potentially faster search vs. potential loss in retrieval accuracy.

### Matryoshka Embeddings

You can use [Matryoshka Representation Learning](../features/matryoshka) for models that support it (like Jina embeddings v3) to truncate dimensions and save space while maintaining good accuracy:

```python
config = {
    "vector_store": {
        "provider": "pgvector",
        "config": {
            "user": "test",
            "password": "123",
            "host": "127.0.0.1",
            "port": "5432",
            "embedding_model_dims": 1024,  # Original dimension
            "matryoshka_dims": 512        # Target dimension after truncation
        }
    }
}
```

This reduces storage requirements and can improve query performance with minimal impact on accuracy.

**Note:** Matryoshka truncation cannot be used together with binary quantization. If both are specified, quantization will take precedence.